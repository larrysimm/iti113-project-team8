{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10575099-4d5e-4a7d-a24f-9920ab88674a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T04:00:50.073389Z",
     "iopub.status.busy": "2025-07-20T04:00:50.073139Z",
     "iopub.status.idle": "2025-07-20T04:00:51.820537Z",
     "shell.execute_reply": "2025-07-20T04:00:51.819770Z",
     "shell.execute_reply.started": "2025-07-20T04:00:50.073352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /opt/conda/lib/python3.12/site-packages (0.3.12)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->kagglehub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->kagglehub) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->kagglehub) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf0be61-aac9-407b-8d16-610207dc7c6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T04:00:51.821646Z",
     "iopub.status.busy": "2025-07-20T04:00:51.821407Z",
     "iopub.status.idle": "2025-07-20T04:00:53.183568Z",
     "shell.execute_reply": "2025-07-20T04:00:53.182783Z",
     "shell.execute_reply.started": "2025-07-20T04:00:51.821621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'punkt_tab' NLTK resource found.\n",
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# # Install and Import Libraries\n",
    "\n",
    "# import kagglehub\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import nltk\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from collections import defaultdict, Counter\n",
    "# import re\n",
    "\n",
    "# # --- IMPORTANT FIX FOR NLTK PUNKT_TAB ---\n",
    "# # Ensure you have the necessary NLTK data.\n",
    "# # Modern NLTK versions (3.8.2+) use 'punkt_tab' instead of 'punkt'.\n",
    "# # The try-except block now checks for 'punkt_tab'.\n",
    "# try:\n",
    "#     nltk.data.find('tokenizers/punkt_tab')\n",
    "#     print(\"'punkt_tab' NLTK resource found.\")\n",
    "# except LookupError: # This is the correct exception for missing NLTK data in newer versions\n",
    "#     print(\"Downloading 'punkt_tab' NLTK resource...\")\n",
    "#     nltk.download('punkt_tab')\n",
    "#     print(\"'punkt_tab' downloaded successfully.\")\n",
    "# except Exception as e: # Catch any other unexpected exceptions\n",
    "#     print(f\"An unexpected error occurred during NLTK data check: {e}\")\n",
    "#     print(\"Attempting to download 'punkt' as a fallback, though 'punkt_tab' is preferred.\")\n",
    "#     try:\n",
    "#         nltk.download('punkt')\n",
    "#         print(\"'punkt' downloaded successfully as a fallback.\")\n",
    "#     except Exception as e_fallback:\n",
    "#         print(f\"Fallback 'punkt' download also failed: {e_fallback}\")\n",
    "\n",
    "\n",
    "# print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e72fb-f5da-4f40-9fb2-5f07d47b6553",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T04:00:53.186701Z",
     "iopub.status.busy": "2025-07-20T04:00:53.186336Z",
     "iopub.status.idle": "2025-07-20T04:00:53.736233Z",
     "shell.execute_reply": "2025-07-20T04:00:53.735434Z",
     "shell.execute_reply.started": "2025-07-20T04:00:53.186676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/sagemaker-user/.cache/kagglehub/datasets/ahmadseloabadi/whatsapp-app-reviews-from-google-play-store/versions/2\n"
     ]
    }
   ],
   "source": [
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"ahmadseloabadi/whatsapp-app-reviews-from-google-play-store\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87add958-52a3-4823-a99f-5f52afb9c7bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T04:00:53.737716Z",
     "iopub.status.busy": "2025-07-20T04:00:53.737300Z",
     "iopub.status.idle": "2025-07-20T04:00:54.683707Z",
     "shell.execute_reply": "2025-07-20T04:00:54.682023Z",
     "shell.execute_reply.started": "2025-07-20T04:00:53.737694Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  \\\n",
      "0  usually , he would be tearing around the livin...   \n",
      "1  but just one look at a minion sent him practic...   \n",
      "2  that had been megan 's plan when she got him d...   \n",
      "3  he 'd seen the movie almost by mistake , consi...   \n",
      "4  she liked to think being surrounded by adults ...   \n",
      "\n",
      "                                   processed_content  \n",
      "0  [usually, he, would, be, tearing, around, the,...  \n",
      "1  [but, just, one, look, at, a, minion, sent, hi...  \n",
      "2  [that, had, been, megan, s, plan, when, she, g...  \n",
      "3  [he, d, seen, the, movie, almost, by, mistake,...  \n",
      "4  [she, liked, to, think, being, surrounded, by,...  \n",
      "Number of reviews: 10000\n"
     ]
    }
   ],
   "source": [
    "# --- REPLACE the KaggleHub download and CSV loading with the same corpus as nextword.ipynb ---\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "# Ensure NLTK punkt is available\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "# Read the same corpus as nextword.ipynb\n",
    "df = pd.read_parquet(\"train-00000-of-00010.parquet\", engine=\"pyarrow\")\n",
    "\n",
    "# Use the same number of lines as in nextword.ipynb\n",
    "numlines = 10000  # Set to match nextword.ipynb\n",
    "corpus = df[\"text\"].dropna().tolist()[:numlines]\n",
    "\n",
    "# Preprocess: lowercase, remove punctuation, tokenize\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Apply preprocessing\n",
    "df_content = pd.DataFrame({'content': corpus})\n",
    "df_content['processed_content'] = df_content['content'].apply(preprocess_text)\n",
    "\n",
    "print(df_content.head())\n",
    "print(f\"Number of reviews: {len(df_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5840085f-80df-48f6-9b52-4ea31e1b28ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T04:00:54.685424Z",
     "iopub.status.busy": "2025-07-20T04:00:54.685054Z",
     "iopub.status.idle": "2025-07-20T04:34:03.664909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting text preprocessing...\n",
      "Text preprocessing complete.\n",
      "\n",
      "Sample of processed content:\n",
      "0    [usually, he, would, be, tearing, around, the,...\n",
      "1    [but, just, one, look, at, a, minion, sent, hi...\n",
      "2    [that, had, been, megan, s, plan, when, she, g...\n",
      "3    [he, d, seen, the, movie, almost, by, mistake,...\n",
      "4    [she, liked, to, think, being, surrounded, by,...\n",
      "Name: processed_content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define Preprocessing Function and Apply\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Cleans and tokenizes text: lowercasing, removing punctuation, and splitting into words.\n",
    "    \"\"\"\n",
    "    if pd.isna(text): # Handle potential NaN values if any slipped through dropna\n",
    "        return []\n",
    "    text = str(text).lower() # Ensure it's a string and lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation (keep alphanumeric and whitespace)\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to all review content\n",
    "print(\"Starting text preprocessing...\")\n",
    "df_content['processed_content'] = df_content['content'].apply(preprocess_text)\n",
    "print(\"Text preprocessing complete.\")\n",
    "\n",
    "# Display a sample of processed content\n",
    "print(\"\\nSample of processed content:\")\n",
    "print(df_content['processed_content'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7650e66-73df-4d5d-8260-34a2cb823ff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T04:39:39.288816Z",
     "iopub.status.busy": "2025-07-20T04:39:39.288179Z",
     "iopub.status.idle": "2025-07-20T04:39:42.734524Z",
     "shell.execute_reply": "2025-07-20T04:39:42.733699Z",
     "shell.execute_reply.started": "2025-07-20T04:39:39.288787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building bigram model...\n",
      "Bigram model built.\n",
      "\n",
      "Sample bigram counts for 'the':\n",
      "[('door', 79), ('way', 66), ('last', 57), ('same', 56), ('first', 51)]\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Build the Bigram Language Model\n",
    "\n",
    "print(\"Building bigram model...\")\n",
    "bigram_model = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for tokens in df_content['processed_content']:\n",
    "    if len(tokens) > 1: # Ensure there are at least two words to form a bigram\n",
    "        for i in range(len(tokens) - 1):\n",
    "            current_word = tokens[i]\n",
    "            next_word = tokens[i+1]\n",
    "            bigram_model[current_word][next_word] += 1\n",
    "print(\"Bigram model built.\")\n",
    "\n",
    "# Optional: Print some sample bigram counts\n",
    "print(\"\\nSample bigram counts for 'the':\")\n",
    "if 'the' in bigram_model:\n",
    "    sorted_the_bigrams = sorted(bigram_model['the'].items(), key=lambda item: item[1], reverse=True)\n",
    "    print(sorted_the_bigrams[:5])\n",
    "else:\n",
    "    print(\"'the' not found in model (unlikely).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98dac5ed-2bba-48bc-a1a4-d74978ef9f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T04:42:21.657715Z",
     "iopub.status.busy": "2025-07-20T04:42:21.657431Z",
     "iopub.status.idle": "2025-07-20T04:42:21.662705Z",
     "shell.execute_reply": "2025-07-20T04:42:21.661950Z",
     "shell.execute_reply.started": "2025-07-20T04:42:21.657695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction function defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Define Prediction Function\n",
    "\n",
    "def predict_next_word(input_word, model, top_n=3):\n",
    "    \"\"\"\n",
    "    Predicts the next most likely word(s) based on the input_word using the bigram model.\n",
    "    \"\"\"\n",
    "    input_word = input_word.lower()\n",
    "    if input_word in model:\n",
    "        # Sort predictions by frequency in descending order\n",
    "        predictions = sorted(model[input_word].items(), key=lambda item: item[1], reverse=True)\n",
    "        # Filter out empty strings or non-alpha words that might have slipped through\n",
    "        clean_predictions = [word for word, count in predictions if word.strip() and word.isalpha()]\n",
    "        return clean_predictions[:top_n]\n",
    "    else:\n",
    "        return [\"No prediction (word not in vocabulary or very rare).\"]\n",
    "\n",
    "print(\"Prediction function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bebc3da-2d73-4e3e-ab89-b3dbedfba1c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T04:42:43.723843Z",
     "iopub.status.busy": "2025-07-20T04:42:43.723395Z",
     "iopub.status.idle": "2025-07-20T04:42:43.742114Z",
     "shell.execute_reply": "2025-07-20T04:42:43.741189Z",
     "shell.execute_reply.started": "2025-07-20T04:42:43.723802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Next Word Prediction Examples ---\n",
      "If you type 'the', the next word could be: ['door', 'way', 'last']\n",
      "If you type 'app', the next word could be: ['No prediction (word not in vocabulary or very rare).']\n",
      "If you type 'good', the next word could be: ['to', 'for', 'idea']\n",
      "If you type 'extraordinary', the next word could be: ['No prediction (word not in vocabulary or very rare).']\n",
      "If you type 'i', the next word could be: ['m', 'was', 'do']\n",
      "If you type 'this', the next word could be: ['is', 'was', 'time']\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Example Usage and Testing\n",
    "\n",
    "print(\"\\n--- Next Word Prediction Examples ---\")\n",
    "\n",
    "# Example 1\n",
    "input_word_1 = \"the\"\n",
    "predictions_1 = predict_next_word(input_word_1, bigram_model)\n",
    "print(f\"If you type '{input_word_1}', the next word could be: {predictions_1}\")\n",
    "\n",
    "# Example 2\n",
    "input_word_2 = \"app\"\n",
    "predictions_2 = predict_next_word(input_word_2, bigram_model)\n",
    "print(f\"If you type '{input_word_2}', the next word could be: {predictions_2}\")\n",
    "\n",
    "# Example 3\n",
    "input_word_3 = \"good\"\n",
    "predictions_3 = predict_next_word(input_word_3, bigram_model)\n",
    "print(f\"If you type '{input_word_3}', the next word could be: {predictions_3}\")\n",
    "\n",
    "# Example 4 (word not in model - might be rare or misspelled)\n",
    "input_word_4 = \"extraordinary\"\n",
    "predictions_4 = predict_next_word(input_word_4, bigram_model)\n",
    "print(f\"If you type '{input_word_4}', the next word could be: {predictions_4}\")\n",
    "\n",
    "# Example 5 (common phrase start)\n",
    "input_word_5 = \"i\"\n",
    "predictions_5 = predict_next_word(input_word_5, bigram_model)\n",
    "print(f\"If you type '{input_word_5}', the next word could be: {predictions_5}\")\n",
    "\n",
    "# Example 6 (another common phrase start)\n",
    "input_word_6 = \"this\"\n",
    "predictions_6 = predict_next_word(input_word_6, bigram_model)\n",
    "print(f\"If you type '{input_word_6}', the next word could be: {predictions_6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df7a11f-e024-473d-9614-794e802ce26a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T04:45:20.623020Z",
     "iopub.status.busy": "2025-07-20T04:45:20.622653Z",
     "iopub.status.idle": "2025-07-20T04:45:20.646082Z",
     "shell.execute_reply": "2025-07-20T04:45:20.645320Z",
     "shell.execute_reply.started": "2025-07-20T04:45:20.622994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Next Word Prediction Examples (Optimized Loop) ---\n",
      "If you type 'the', the next word could be: ['door', 'way', 'last']\n",
      "If you type 'app', the next word could be: ['No prediction (word not in vocabulary or very rare).']\n",
      "If you type 'good', the next word could be: ['to', 'for', 'idea']\n",
      "If you type 'extraordinary', the next word could be: ['No prediction (word not in vocabulary or very rare).']\n",
      "If you type 'i', the next word could be: ['m', 'was', 'do']\n",
      "If you type 'this', the next word could be: ['is', 'was', 'time']\n",
      "If you type 'whatsapp', the next word could be: ['No prediction (word not in vocabulary or very rare).']\n",
      "If you type 'update', the next word could be: ['No prediction (word not in vocabulary or very rare).']\n",
      "If you type 'messages', the next word could be: ['first', 'were']\n",
      "\n",
      "--- End of Examples ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Optimized Example Usage and Testing with a loop\n",
    "\n",
    "print(\"\\n--- Next Word Prediction Examples (Optimized Loop) ---\")\n",
    "\n",
    "# Define a list of input words to test\n",
    "test_words = [\n",
    "    \"the\",\n",
    "    \"app\",\n",
    "    \"good\",\n",
    "    \"extraordinary\", # Word likely not in vocabulary\n",
    "    \"i\",\n",
    "    \"this\",\n",
    "    \"whatsapp\", # Another common word in reviews\n",
    "    \"update\",   # A word related to app changes\n",
    "    \"messages\"  # A word related to app function\n",
    "]\n",
    "\n",
    "for word in test_words:\n",
    "    predictions = predict_next_word(word, bigram_model)\n",
    "    print(f\"If you type '{word}', the next word could be: {predictions}\")\n",
    "\n",
    "print(\"\\n--- End of Examples ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34bd3e93-e9f4-49be-bc98-f4ec92b66497",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T04:49:59.742822Z",
     "iopub.status.busy": "2025-07-20T04:49:59.742428Z",
     "iopub.status.idle": "2025-07-20T04:50:01.842235Z",
     "shell.execute_reply": "2025-07-20T04:50:01.833749Z",
     "shell.execute_reply.started": "2025-07-20T04:49:59.742788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Next Word Prediction Evaluation from Corpus ---\n",
      "Total bigrams in corpus: 110075\n",
      "Testing with 50 random bigrams from the corpus.\n",
      "\n",
      "Input: 'anymore'\n",
      "Actual Next Word: 'dropping'\n",
      "Model Predictions (Top 3): ['the', 'erectile', 'not']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'this'\n",
      "Actual Next Word: 'one'\n",
      "Model Predictions (Top 3): ['is', 'was', 'time']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'in'\n",
      "Actual Next Word: 'place'\n",
      "Model Predictions (Top 3): ['the', 'a', 'her']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'especially'\n",
      "Actual Next Word: 'if'\n",
      "Model Predictions (Top 3): ['since', 'if', 'after']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "Input: 'and'\n",
      "Actual Next Word: 'then'\n",
      "Model Predictions (Top 3): ['i', 'then', 'she']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "Input: 'is'\n",
      "Actual Next Word: 'the'\n",
      "Model Predictions (Top 3): ['nt', 'that', 'a']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'behind'\n",
      "Actual Next Word: 'my'\n",
      "Model Predictions (Top 3): ['her', 'him', 'the']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'for'\n",
      "Actual Next Word: 'you'\n",
      "Model Predictions (Top 3): ['the', 'a', 'her']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'need'\n",
      "Actual Next Word: 'me'\n",
      "Model Predictions (Top 3): ['to', 'a', 'is']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'appearance'\n",
      "Actual Next Word: 'and'\n",
      "Model Predictions (Top 3): ['and']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "Input: 'the'\n",
      "Actual Next Word: 'hall'\n",
      "Model Predictions (Top 3): ['door', 'way', 'last']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'casey'\n",
      "Actual Next Word: 'questioned'\n",
      "Model Predictions (Top 3): ['snorted', 'grinned', 'laughed']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'settling'\n",
      "Actual Next Word: 'in'\n",
      "Model Predictions (Top 3): ['in']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "Input: 'talk'\n",
      "Actual Next Word: 'to'\n",
      "Model Predictions (Top 3): ['to', 'about', 'with']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "Input: 'of'\n",
      "Actual Next Word: 'all'\n",
      "Model Predictions (Top 3): ['the', 'her', 'his']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'as'\n",
      "Actual Next Word: 'a'\n",
      "Model Predictions (Top 3): ['she', 'he', 'i']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'that'\n",
      "Actual Next Word: 'silenced'\n",
      "Model Predictions (Top 3): ['s', 'i', 'she']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'gaze'\n",
      "Actual Next Word: 'seemed'\n",
      "Model Predictions (Top 3): ['from', 'to', 'over']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'time'\n",
      "Actual Next Word: 'and'\n",
      "Model Predictions (Top 3): ['i', 'to', 'she']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'interns'\n",
      "Actual Next Word: 'not'\n",
      "Model Predictions (Top 3): ['not']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "Input: 'her'\n",
      "Actual Next Word: 'aunts'\n",
      "Model Predictions (Top 3): ['head', 'eyes', 'to']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'me'\n",
      "Actual Next Word: 'i'\n",
      "Model Predictions (Top 3): ['to', 'a', 'and']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'dab'\n",
      "Actual Next Word: 'her'\n",
      "Model Predictions (Top 3): ['her']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "Input: 'with'\n",
      "Actual Next Word: 'a'\n",
      "Model Predictions (Top 3): ['a', 'her', 'the']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "Input: 'if'\n",
      "Actual Next Word: 'you'\n",
      "Model Predictions (Top 3): ['you', 'i', 'he']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "Input: 'other'\n",
      "Actual Next Word: 'men'\n",
      "Model Predictions (Top 3): ['hand', 'side', 'and']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'head'\n",
      "Actual Next Word: 'no'\n",
      "Model Predictions (Top 3): ['back', 'at', 'and']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'never'\n",
      "Actual Next Word: 'had'\n",
      "Model Predictions (Top 3): ['had', 'been', 'wanted']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "Input: 'as'\n",
      "Actual Next Word: 'long'\n",
      "Model Predictions (Top 3): ['she', 'he', 'i']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'patted'\n",
      "Actual Next Word: 'megan'\n",
      "Model Predictions (Top 3): ['her', 'pesh', 'his']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'truly'\n",
      "Actual Next Word: 'hers'\n",
      "Model Predictions (Top 3): ['wanted', 'knew', 'went']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'he'\n",
      "Actual Next Word: 'knew'\n",
      "Model Predictions (Top 3): ['was', 'had', 's']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'i'\n",
      "Actual Next Word: 'did'\n",
      "Model Predictions (Top 3): ['m', 'was', 'do']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'uh'\n",
      "Actual Next Word: 'oh'\n",
      "Model Predictions (Top 3): ['huh', 'i', 'we']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'good'\n",
      "Actual Next Word: 'doctor'\n",
      "Model Predictions (Top 3): ['to', 'for', 'idea']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'so'\n",
      "Actual Next Word: 'mmm'\n",
      "Model Predictions (Top 3): ['i', 'much', 'you']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'grinding'\n",
      "Actual Next Word: 'my'\n",
      "Model Predictions (Top 3): ['to', 'my']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "Input: 'of'\n",
      "Actual Next Word: 'chocolate'\n",
      "Model Predictions (Top 3): ['the', 'her', 'his']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'what'\n",
      "Actual Next Word: 'should'\n",
      "Model Predictions (Top 3): ['i', 's', 'you']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'about'\n",
      "Actual Next Word: 'you'\n",
      "Model Predictions (Top 3): ['her', 'to', 'that']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'idea'\n",
      "Actual Next Word: 'has'\n",
      "Model Predictions (Top 3): ['of', 'that', 'i']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'had'\n",
      "Actual Next Word: 'now'\n",
      "Model Predictions (Top 3): ['been', 'nt', 'to']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'caring'\n",
      "Actual Next Word: 'and'\n",
      "Model Predictions (Top 3): ['and']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "Input: 'take'\n",
      "Actual Next Word: 'after'\n",
      "Model Predictions (Top 3): ['a', 'care', 'you']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'a'\n",
      "Actual Next Word: 'plane'\n",
      "Model Predictions (Top 3): ['little', 'few', 'man']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'she'\n",
      "Actual Next Word: 'could'\n",
      "Model Predictions (Top 3): ['was', 'had', 'could']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "Input: 'and'\n",
      "Actual Next Word: 'leading'\n",
      "Model Predictions (Top 3): ['i', 'then', 'she']\n",
      "Status: INCORRECT (Actual word NOT in top predictions)\n",
      "\n",
      "Input: 'excuse'\n",
      "Actual Next Word: 'me'\n",
      "Model Predictions (Top 3): ['me']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "Input: 'for'\n",
      "Actual Next Word: 'the'\n",
      "Model Predictions (Top 3): ['the', 'a', 'her']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "Input: 'at'\n",
      "Actual Next Word: 'the'\n",
      "Model Predictions (Top 3): ['the', 'her', 'him']\n",
      "Status: CORRECT (Actual word in top predictions)\n",
      "\n",
      "--- Prediction Summary ---\n",
      "Total predictions made: 50\n",
      "Correct (Top 1 Prediction): 12 / 50 (24.00%)\n",
      "Correct (Any in Top 3 Predictions): 16 / 50 (32.00%)\n",
      "\n",
      "--- End of Evaluation ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Optimized Example Usage and Evaluation from Corpus\n",
    "\n",
    "print(\"\\n--- Next Word Prediction Evaluation from Corpus ---\")\n",
    "\n",
    "# We'll collect a sample of (current_word, actual_next_word) pairs from the corpus\n",
    "# to test our model.\n",
    "# To avoid testing on every single bigram (which can be very large and slow),\n",
    "# let's randomly sample some bigrams from our processed content.\n",
    "\n",
    "# Flatten all processed tokens into a single list\n",
    "all_tokens = [word for sublist in df_content['processed_content'] for word in sublist]\n",
    "\n",
    "# Create actual bigrams from the flattened list\n",
    "corpus_bigrams = []\n",
    "if len(all_tokens) > 1:\n",
    "    for i in range(len(all_tokens) - 1):\n",
    "        corpus_bigrams.append((all_tokens[i], all_tokens[i+1]))\n",
    "\n",
    "print(f\"Total bigrams in corpus: {len(corpus_bigrams)}\")\n",
    "\n",
    "# Sample a smaller number of bigrams for testing to keep it manageable\n",
    "# Adjust num_samples as needed for performance vs. comprehensiveness\n",
    "num_samples = min(50, len(corpus_bigrams)) # Test up to 50 samples or all if less than 50\n",
    "import random\n",
    "test_samples = random.sample(corpus_bigrams, num_samples) if num_samples > 0 else []\n",
    "\n",
    "print(f\"Testing with {len(test_samples)} random bigrams from the corpus.\")\n",
    "\n",
    "correct_in_top_1 = 0\n",
    "correct_in_top_3 = 0 # Check if the actual next word is in the top 3 predictions\n",
    "total_predictions = 0\n",
    "\n",
    "if not test_samples:\n",
    "    print(\"No test samples available. Corpus might be too small or empty after preprocessing.\")\n",
    "else:\n",
    "    for current_word, actual_next_word in test_samples:\n",
    "        total_predictions += 1\n",
    "        predictions = predict_next_word(current_word, bigram_model, top_n=3)\n",
    "\n",
    "        print(f\"\\nInput: '{current_word}'\")\n",
    "        print(f\"Actual Next Word: '{actual_next_word}'\")\n",
    "        print(f\"Model Predictions (Top 3): {predictions}\")\n",
    "\n",
    "        if actual_next_word in predictions:\n",
    "            correct_in_top_3 += 1\n",
    "            if actual_next_word == predictions[0]: # Check if it's the very first prediction\n",
    "                correct_in_top_1 += 1\n",
    "            print(\"Status: CORRECT (Actual word in top predictions)\")\n",
    "        else:\n",
    "            print(\"Status: INCORRECT (Actual word NOT in top predictions)\")\n",
    "\n",
    "    # Calculate and print accuracy\n",
    "    accuracy_top_1 = (correct_in_top_1 / total_predictions) * 100 if total_predictions > 0 else 0\n",
    "    accuracy_top_3 = (correct_in_top_3 / total_predictions) * 100 if total_predictions > 0 else 0\n",
    "\n",
    "    print(\"\\n--- Prediction Summary ---\")\n",
    "    print(f\"Total predictions made: {total_predictions}\")\n",
    "    print(f\"Correct (Top 1 Prediction): {correct_in_top_1} / {total_predictions} ({accuracy_top_1:.2f}%)\")\n",
    "    print(f\"Correct (Any in Top 3 Predictions): {correct_in_top_3} / {total_predictions} ({accuracy_top_3:.2f}%)\")\n",
    "\n",
    "print(\"\\n--- End of Evaluation ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b85fc-0c69-4e38-aeb5-c0f959d74574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
